{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "Project1_Kusum.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-uZqoPJRNveY"
      },
      "source": [
        "# Project: 'Fruit Image Classification using Transfer Learning' \n",
        "## (Kusum Panchal and Arun Kumar Ramakrishnan)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BZgwbWme218T"
      },
      "source": [
        "We will train a new model that is able to recognize fresh and rotten fruit. We will use the combination of transfer learning, data augmentation, and fine tuning.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BwYpClBQODPa"
      },
      "source": [
        "## The Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TztYjW5Y218V"
      },
      "source": [
        "In this exercise, we will train a model to recognize fresh and rotten fruits. The dataset comes from [Kaggle](https://www.kaggle.com/sriramr/fruits-fresh-and-rotten-for-classification), a great place to go if you're interested in starting a project after this class. The dataset structure is in the `data/fruits` folder. There are 6 categories of fruits: fresh apples, fresh oranges, fresh bananas, rotten apples, rotten oranges, and rotten bananas. This will mean that our model will require an output layer of 6 neurons to do the categorization successfully. We'll compile the model with `categorical_crossentropy`, as we have more than two categories."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qieOK9C8218X"
      },
      "source": [
        "## Load ImageNet Base Model\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LQTOxZPL218Y"
      },
      "source": [
        "We will use Transfer Learning here. We will start with a model pretrained on ImageNet; load the model with the correct weights, set an input shape, and choose to remove the last layers of the model. The images have three dimensions: a height, and width, and a number of channels. Because these pictures are in color, there will be three channels for red, green, and blue. We've filled in the input shape for you. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vp4j1TcC218a",
        "outputId": "fec20812-8377-4e0d-fd03-6927062ad3a5"
      },
      "source": [
        "from tensorflow import keras\n",
        "\n",
        "base_model = keras.applications.VGG16(\n",
        "    weights='imagenet',   \n",
        "    input_shape=(224, 224, 3),\n",
        "    include_top=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 1s 0us/step\n",
            "58900480/58889256 [==============================] - 1s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D-Lb6tRV218d"
      },
      "source": [
        "## Freeze Base Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4bYx0612218f"
      },
      "source": [
        "We will freeze the base model, so that all the learning from the ImageNet dataset does not get destroyed in the initial training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XUQUR-SA218f"
      },
      "source": [
        "# Freeze base model\n",
        "base_model.trainable = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "msgqA8Ga218g"
      },
      "source": [
        "## Add Layers to Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mp9De3_H218h"
      },
      "source": [
        "Now it's time to add layers to the pretrained model. We need to pay close attention to the last dense layer and make sure it has the correct number of neurons to classify the different types of fruit."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MzYOcS4D218h"
      },
      "source": [
        "# Create inputs with correct shape\n",
        "inputs = keras.Input(shape=(224, 224, 3))\n",
        "\n",
        "x = base_model(inputs, training=False)\n",
        "\n",
        "# Add pooling layer or flatten layer\n",
        "x = keras.layers.GlobalAveragePooling2D()(x)\n",
        "\n",
        "# Add final dense layer\n",
        "outputs = keras.layers.Dense(1, activation = 'softmax')(x)\n",
        "\n",
        "# Combine inputs and outputs to create model\n",
        "model = keras.Model(inputs,outputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M7rzCxNF218i"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gStIXBvF218k"
      },
      "source": [
        "## Compile Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yRIBlrQi218k"
      },
      "source": [
        "Now, we will compile the model with loss and metrics options. We're training on a number of different categories, rather than a binary classification problem."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C6rtu-DV218l"
      },
      "source": [
        "model.compile(optimizer=keras.optimizers.RMSprop(learning_rate = .00001),  # Very low learning rate\n",
        "              loss=keras.losses.CategoricalCrossentropy(),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RnAIH-YF218m"
      },
      "source": [
        "## Augment the Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZlswSrKw218m"
      },
      "source": [
        "Further, we can try to augment the data to improve the dataset. Reference: [Keras ImageDataGenerator class](https://keras.io/api/preprocessing/image/#imagedatagenerator-class). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vXMPutQ7218n"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "        samplewise_center=True,  # set each sample mean to 0\n",
        "        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "        zoom_range = 0.1, # Randomly zoom image \n",
        "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
        "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
        "        horizontal_flip=True,  # randomly flip images\n",
        "        vertical_flip=False) # we don't expect Bo to be upside-down so we will not flip vertically"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HU2JOBqC218o"
      },
      "source": [
        "## Load Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O_g9FxNZ218o"
      },
      "source": [
        "Now we will load the train and validation datasets. It's important to pick the right folders, as well as the right `target_size` of the images (it needs to match the height and width input of the model we've created). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4TeyTLT4218p"
      },
      "source": [
        "# load and iterate training dataset\n",
        "train_it = datagen.flow_from_directory('data/fruits/train/', \n",
        "                                       target_size=(224, 224), \n",
        "                                       color_mode='rgb', \n",
        "                                       class_mode='categorical', \n",
        "                                       batch_size=8)\n",
        "# load and iterate validation dataset\n",
        "valid_it = datagen.flow_from_directory('data/fruits/valid/', \n",
        "                                      target_size=(224, 224), \n",
        "                                      color_mode='rgb', \n",
        "                                      class_mode='categorical', \n",
        "                                      batch_size=8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-5aNQ4Pa218q"
      },
      "source": [
        "## Train the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hY995qbQ218q"
      },
      "source": [
        "Now, we will pass the `train` and `valid` iterators into the `fit` function, as well as setting your desired number of epochs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rN7ZJWz6218q"
      },
      "source": [
        "model.fit(train_it,\n",
        "          validation_data=valid_it,\n",
        "          steps_per_epoch=train_it.samples/train_it.batch_size,\n",
        "          validation_steps=valid_it.samples/valid_it.batch_size,\n",
        "          epochs=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hDFyQKhA218r"
      },
      "source": [
        "## Unfreeze Model for Fine Tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZNEOHHOo218r"
      },
      "source": [
        "We can now fine tune the model further with a very low learning rate. For that, we first need to unfreeze the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OqpHrb6T218r"
      },
      "source": [
        "# Unfreeze the base model\n",
        "base_model.trainable = False\n",
        "\n",
        "# Compile the model with a low learning rate\n",
        "model.compile(optimizer=keras.optimizers.RMSprop(learning_rate = .00001),\n",
        "              loss = keras.losses.CategoricalCrossentropy() , metrics = ['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2pGWWePP218s"
      },
      "source": [
        "model.fit(train_it,\n",
        "          validation_data=valid_it,\n",
        "          steps_per_epoch=train_it.samples/train_it.batch_size,\n",
        "          validation_steps=valid_it.samples/valid_it.batch_size,\n",
        "          epochs=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZoD5kaGr218s"
      },
      "source": [
        "## Evaluate the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7mFn_oP-218t"
      },
      "source": [
        "The evaluate function will return a tuple, where the first value is the loss, and the second value is the accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7AILSICp218t"
      },
      "source": [
        "model.evaluate(valid_it, steps=valid_it.samples/valid_it.batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}